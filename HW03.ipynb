{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7eb04f2f",
   "metadata": {},
   "source": [
    "# HW03 - Fine-tuning on Animal Dataset\n",
    "\n",
    "This notebook implements fine-tuning of a pre-trained model on my custom animal dataset (cats, dogs, rabbits, capybaras, owls).\n",
    "\n",
    "**Dataset**: Animals dataset with 5 classes\n",
    "**Task**: Fine-tune a pre-trained model for image classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c54ac2d",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488a06aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "# Ignore palette warnings\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=\"Palette images with Transparency expressed in bytes should be converted to RGBA images\",\n",
    "    category=UserWarning\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c679cee0",
   "metadata": {},
   "source": [
    "## 2. Data Preparation\n",
    "\n",
    "Load the dataset that was prepared in the previous notebooks. The dataset is already organized in the correct train/test structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33bf8783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the dataset (using the animals_dataset created in previous notebooks)\n",
    "path = Path('./animals_dataset/train')\n",
    "\n",
    "# Create data loaders\n",
    "dls = ImageDataLoaders.from_folder(\n",
    "    path,                 # Path to the train folder\n",
    "    train='.',            # Use the entire train folder for splitting\n",
    "    valid_pct=0.2,        # 20% of the data will be used for validation\n",
    "    seed=42,              # Set a seed for reproducibility\n",
    "    item_tfms=Resize(460),# Resize the images to 460x460\n",
    "    batch_tfms=aug_transforms(size=224, min_scale=0.75), # Data augmentation \n",
    "    bs=32                 # Batch size 32 (reduced for better performance)\n",
    ")\n",
    "\n",
    "print(f\"Number of classes: {len(dls.vocab)}\")\n",
    "print(f\"Classes: {dls.vocab}\")\n",
    "print(f\"Training samples: {len(dls.train_ds)}\")\n",
    "print(f\"Validation samples: {len(dls.valid_ds)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc69c463",
   "metadata": {},
   "source": [
    "## 3. Show Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aed9657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show a batch of images\n",
    "dls.show_batch(max_n=9, figsize=(10, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f82cb75",
   "metadata": {},
   "source": [
    "## 4. Model Selection and Learning Rate Finding\n",
    "\n",
    "Using ResNet18 as the base model - it's a good balance between performance and speed for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797d88b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a vision learner with ResNet18\n",
    "learn = vision_learner(dls, resnet18, metrics=error_rate)\n",
    "\n",
    "# Find the optimal learning rate\n",
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61987dea",
   "metadata": {},
   "source": [
    "## 5. Fine-tuning the Model\n",
    "\n",
    "Based on the learning rate finder, I'll set an appropriate learning rate and train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1594d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set optimal learning rate (adjust based on lr_find results)\n",
    "lr = 1e-3  # This is a good starting point, adjust based on lr_find plot\n",
    "epochs = 5  # Number of epochs for fine-tuning\n",
    "\n",
    "print(f\"Training with learning rate: {lr} for {epochs} epochs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb0a25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a fresh learner and fine-tune\n",
    "learn = vision_learner(dls, resnet18, metrics=error_rate)\n",
    "learn.fine_tune(epochs, lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2456a3d",
   "metadata": {},
   "source": [
    "## 6. Model Evaluation\n",
    "\n",
    "Let's evaluate how well our model performs on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f679772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create interpretation object\n",
    "interp = ClassificationInterpretation.from_learner(learn)\n",
    "\n",
    "# Plot confusion matrix\n",
    "interp.plot_confusion_matrix(figsize=(8, 8), dpi=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7b2827",
   "metadata": {},
   "source": [
    "## 7. Analyze Misclassifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e00abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the most confused/misclassified images\n",
    "interp.plot_top_losses(9, figsize=(13, 13))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e47a9d",
   "metadata": {},
   "source": [
    "## 8. Test on Test Set\n",
    "\n",
    "Now let's test our model on the separate test set that we prepared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc01e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a test DataLoader\n",
    "test_path = Path('./animals_dataset/test')\n",
    "test_dl = learn.dls.test_dl(get_image_files(test_path))\n",
    "\n",
    "print(f\"Test set size: {len(test_dl.items)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a76f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions on test set\n",
    "preds, targets = learn.get_preds(dl=test_dl)\n",
    "pred_labels = torch.argmax(preds, dim=1)\n",
    "\n",
    "# Get class names\n",
    "class_names = learn.dls.vocab\n",
    "\n",
    "# Convert predictions to class names\n",
    "pred_class_names = [class_names[i] for i in pred_labels]\n",
    "true_class_names = [Path(t).parent.name for t in test_dl.items]\n",
    "\n",
    "print(f\"Sample predictions:\")\n",
    "for i in range(min(10, len(pred_class_names))):\n",
    "    status = \"✓\" if true_class_names[i] == pred_class_names[i] else \"✗\"\n",
    "    print(f\"{status} True: {true_class_names[i]:10} | Predicted: {pred_class_names[i]:10}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b5abef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate test accuracy\n",
    "from statistics import mean\n",
    "\n",
    "test_accuracy = mean([actual == predicted for actual, predicted in zip(true_class_names, pred_class_names)])\n",
    "test_error_rate = 1 - test_accuracy\n",
    "\n",
    "print(f\"\\n🎯 TEST RESULTS:\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
    "print(f\"Test Error Rate: {test_error_rate:.4f} ({test_error_rate*100:.2f}%)\")\n",
    "\n",
    "# Per-class accuracy\n",
    "print(f\"\\n📊 PER-CLASS RESULTS:\")\n",
    "for class_name in class_names:\n",
    "    class_true = [i for i, true_class in enumerate(true_class_names) if true_class == class_name]\n",
    "    if len(class_true) > 0:\n",
    "        class_correct = sum([true_class_names[i] == pred_class_names[i] for i in class_true])\n",
    "        class_accuracy = class_correct / len(class_true)\n",
    "        print(f\"{class_name:10}: {class_accuracy:.4f} ({class_accuracy*100:.2f}%) - {class_correct}/{len(class_true)} correct\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb1de6c",
   "metadata": {},
   "source": [
    "## 9. Save the Model\n",
    "\n",
    "Export the trained model for later use in Gradio app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc175a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the model\n",
    "model_path = 'animal_classifier_model.pkl'\n",
    "learn.export(model_path)\n",
    "\n",
    "print(f\"✅ Model saved as: {model_path}\")\n",
    "print(f\"📁 Model file size: {Path(model_path).stat().st_size / (1024*1024):.2f} MB\")\n",
    "print(f\"\\n🚀 This model is ready for deployment in Gradio!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df953452",
   "metadata": {},
   "source": [
    "## 10. Model Summary\n",
    "\n",
    "Let's summarize what we've accomplished."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7c60c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"🎉 FINE-TUNING COMPLETE!\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"📊 Dataset: 5-class animal classifier\")\n",
    "print(f\"🏗️  Model: ResNet18 (fine-tuned)\")\n",
    "print(f\"📝 Classes: {', '.join(class_names)}\")\n",
    "print(f\"🎯 Training completed successfully!\")\n",
    "print(f\"💾 Model exported for Gradio deployment\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"\\n📋 NEXT STEPS:\")\n",
    "print(f\"1. ✅ Fine-tuning completed\")\n",
    "print(f\"2. 🔄 Create Gradio app for deployment\")\n",
    "print(f\"3. 🚀 Deploy to HuggingFace Spaces\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
